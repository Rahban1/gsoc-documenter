var documenterSearchIndex = {"docs":
[{"location":"improving_tokenizer/#Updating-Tokenizer","page":"Updating Tokenizer","title":"Updating Tokenizer","text":"","category":"section"},{"location":"improving_tokenizer/#Understanding-the-task","page":"Updating Tokenizer","title":"Understanding the task","text":"","category":"section"},{"location":"improving_tokenizer/","page":"Updating Tokenizer","title":"Updating Tokenizer","text":"A tokenizer is a component of a search engine that processes text by breaking it down into smaller units called tokens. These tokens are then indexed and used to match search queries against the content.","category":"page"},{"location":"improving_tokenizer/","page":"Updating Tokenizer","title":"Updating Tokenizer","text":"Right now the tokenize function in the repository in assets/html/js/search.js is :","category":"page"},{"location":"improving_tokenizer/","page":"Updating Tokenizer","title":"Updating Tokenizer","text":"    tokenize: (string) => string.split(/[\\s\\-\\.]+/)","category":"page"},{"location":"improving_tokenizer/","page":"Updating Tokenizer","title":"Updating Tokenizer","text":"It splits the string into tokens using regular expression that match spaces (\\s), hyphens (-), and dots (.) as delimiters. Consider somebody search for tasklocalstorage, a default tokenizer will split it into the following tokens “task”, “local”, “storage” While this works well for general text, it can cause problems when searching for programming related content, especially in languages like Julia where identifiers often contain underscores and are meant to be treated as a single cohesive unit.","category":"page"},{"location":"improving_tokenizer/","page":"Updating Tokenizer","title":"Updating Tokenizer","text":"Some problems that can arise from this approach is :","category":"page"},{"location":"improving_tokenizer/","page":"Updating Tokenizer","title":"Updating Tokenizer","text":"Loss of context\nReduced precision\nPoor user experience","category":"page"},{"location":"improving_tokenizer/#The-problem","page":"Updating Tokenizer","title":"The problem","text":"","category":"section"},{"location":"improving_tokenizer/","page":"Updating Tokenizer","title":"Updating Tokenizer","text":"The old tokenizer was too simple and caused these issues:","category":"page"},{"location":"improving_tokenizer/","page":"Updating Tokenizer","title":"Updating Tokenizer","text":"Problem 1: Lost Important Julia Syntax\nWhat happened when someone searched for \"Base.sort\": \"Base.sort function\" → [\"Base\", \"sort\", \"function\"]\nLost the connection between \"Base\" and \"sort\"\nWhy this is bad: Julia has special syntax like Base.sort where the dot (.) connects the module name to the function name. The old tokenizer split on dots, so it couldn't find \"Base.sort\" when you searched for it!\nProblem 2: Operators Got Lost\nWhen someone searched for \"^\" (power operator): \"Use ^ operator\" → [\"Use\", \"\", \"operator\"] The \"^\" symbol disappeared!\nProblem 3: Macros Broken Apart\nWhen someone searched for \"@time\" (a Julia macro): \"@time macro\" → [\"\", \"time\", \"macro\"] Lost the \"@\" symbol that makes it a macro!","category":"page"},{"location":"improving_tokenizer/#Solution","page":"Updating Tokenizer","title":"Solution","text":"","category":"section"},{"location":"improving_tokenizer/","page":"Updating Tokenizer","title":"Updating Tokenizer","text":"Change 1: Improving on the custom trimmer","category":"page"},{"location":"improving_tokenizer/","page":"Updating Tokenizer","title":"Updating Tokenizer","text":"right now the trimmer is :","category":"page"},{"location":"improving_tokenizer/","page":"Updating Tokenizer","title":"Updating Tokenizer","text":"  word = word\n    .replace(/^[^a-zA-Z0-9@!]+/, \"\")\n    .replace(/[^a-zA-Z0-9@!]+$/, \"\")","category":"page"},{"location":"improving_tokenizer/","page":"Updating Tokenizer","title":"Updating Tokenizer","text":"Basically, what this is doing is removing every character which is not uppercase letters, lowercase letters, numbers, and two symbols '@' and '!' from the beginning and end of the query","category":"page"},{"location":"improving_tokenizer/","page":"Updating Tokenizer","title":"Updating Tokenizer","text":"but the problem is what if somebody search for just '^' it would result nothing","category":"page"},{"location":"improving_tokenizer/","page":"Updating Tokenizer","title":"Updating Tokenizer","text":"Change 2: Intelligent Pattern Matching\nI completely rewrote the tokenizer to understand Julia's special syntax. Here's what I did:","category":"page"},{"location":"improving_tokenizer/","page":"Updating Tokenizer","title":"Updating Tokenizer","text":"    // Julia-aware tokenization that preserves meaningful syntax elements\n    tokenize: (string) => {\n      const tokens = [];\n      let remaining = string;\n      \n      // Julia-specific patterns to preserve as complete tokens\n      const patterns = [\n        // Module qualified names (e.g., Base.sort, Module.Submodule.function)\n        /\\b[A-Z][A-Za-z0-9_]*(?:\\.[A-Z][A-Za-z0-9_]*)*\\.[a-z_][A-Za-z0-9_!]*\\b/g,\n        // Macro calls (e.g., @time, @async)\n        /@[A-Za-z_][A-Za-z0-9_]*/g,\n        // Type parameters (e.g., Array{T,N}, Vector{Int})\n        /\\b[A-Z][A-Za-z0-9_]*\\{[^}]+\\}/g,\n        // Function names with module qualification (e.g., Base.+, Base.:^)\n        /\\b[A-Z][A-Za-z0-9_]*\\.:[A-Za-z0-9_!+\\-*/^&|%<>=.]+/g,\n        // Operators as complete tokens (e.g., !=, &&, ||, ^, .=, ->)\n        /[!<>=+\\-*/^&|%:.]+/g,\n        // Function signatures with type annotations (e.g., f(x::Int))\n        /\\b[a-z_][A-Za-z0-9_!]*\\([^)]*::[^)]*\\)/g,\n        // Regular identifiers and function names\n        /\\b[A-Za-z_][A-Za-z0-9_!]*\\b/g,\n        // Numbers (integers, floats, scientific notation)\n        /\\b\\d+(?:\\.\\d+)?(?:[eE][+-]?\\d+)?\\b/g\n      ];\n      \n      // Apply patterns in order of specificity (most specific first)\n      for (const pattern of patterns) {\n        pattern.lastIndex = 0; // Reset regex state\n        let match;\n        while ((match = pattern.exec(remaining)) !== null) {\n          const token = match[0].trim();\n          if (token && !tokens.includes(token)) {\n            tokens.push(token);\n          }\n        }\n      }\n      \n      // Also split on common delimiters for any remaining content\n      const basicTokens = remaining.split(/[\\s\\-,;()[\\]{}]+/).filter(t => t.trim());\n      for (const token of basicTokens) {\n        if (token && !tokens.includes(token)) {\n          tokens.push(token);\n        }\n      }\n      \n      return tokens.filter(token => token.length > 0);\n    },","category":"page"},{"location":"adding_search_benchmarks/#Adding-Search-Benchmarks","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"","category":"section"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"We had our first meeting, and we discussed what would be the flow of the entire internshiop and also discussed how to go about the first deliverable as per the proposal which is Adding Search Benchmarks.  ","category":"page"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"We discussed what should be the language of choice for writing scripts for benchmarking, we had two possible candidates, one was Julia (for obvious reasons, since the whole repo is in Julia) and the other one was JavaScript since the search functionality is implemented in JavaScript so it would be easier to interact with the search functionality.  ","category":"page"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"We talked about it and thought of JavaScript as a better choice but now I think of it, I belive the barebone architecture for benchmarks should be in Julia only so that in future if anybody want to add more benchmarks or new tests they can do it easily as I am expecting most of the people coming in the Documenter repo are coming from Julia background and as far as talking to the JavaScript based search functionality we can see how to talk it through Julin in coming days.","category":"page"},{"location":"adding_search_benchmarks/#Creating-query-structure","page":"Adding Search Benchmarks","title":"Creating query structure","text":"","category":"section"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"First we'll create a new directory in test folder, I have named it search. Inside it I have created the first file named test_queries.jl","category":"page"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"The file structure look like this :","category":"page"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"test/\n├─search/\n│   └─test_queries.jl\n...","category":"page"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"I started with creating a basic struct which stores the search query and what should be the expected docs in the following manner :","category":"page"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"struct TestQuery\n    query::String\n    expected_docs::Vector{String}\nend","category":"page"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"we can then compare it with the actual result and find out the different benchmarks.","category":"page"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"Now we can create different groups of queries like basic queries or queries specific to Julia syntax and if anybody from the community want to test some queries specific to their usecase, they can do it easily. We can then use them all together using something like vcat which will concatenate all the arrays into one","category":"page"},{"location":"adding_search_benchmarks/#Evaluation","page":"Adding Search Benchmarks","title":"Evaluation","text":"","category":"section"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"For now, I am using three metrics for calculating benchmarks namely :","category":"page"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"Precision \nmeasures how many of the returned results are relevant.\nExample: if you returned 5 docs, out of which 3 are relevant, precision = 3/5 = 0.6.\nRecall \nmeasures how many of the true relevant documents were found in the result.\nExample: if there were 4 relevant docs and you returned 3 of them, recall = 3/4 = 0.75.\nF1 Score \nharmonic mean of precision and recall.\nthis balances precision and recall in a single number.\nF_1 = 2 times fractextprecision times textrecalltextprecision + textrecall","category":"page"},{"location":"adding_search_benchmarks/#Helper-functions","page":"Adding Search Benchmarks","title":"Helper functions","text":"","category":"section"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"Now let's create a function that evaluate all these metrics for a single query","category":"page"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"It'll look something like this :","category":"page"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"function evaluate_query(search_function, query::TestQuery)\n    results = search_function(query.query)\n\n    precision = calculate_precision(results, query.expected_docs)\n    recall = calculate_recall(results, query.expected_docs)\n    f1 = calculate_f1(precision, recall)\n\n    return Dict(\n        \"query\" => query.query,\n        \"precision\" => precision,\n        \"recall\" => recall,\n        \"f1\" => f1,\n        \"expected\" => query.expected_docs,\n        \"actual\" => results\n    )\nend","category":"page"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"This will return a dictionary that have all the relevant results. We still have to create the search function that will search the query in our actual search implementation.","category":"page"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"This looks good, now we need to create a function that evaluate all metrics for a suite of queries, which would essentially be calling the evaluate_query function for array of queries, and then calculating the mean of all results for each metric and return a dictionary similar to evaluate_query function","category":"page"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"It look something like this : ","category":"page"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"function evaluate_all(search_function, queries)\n    results = [evaluate_query(search_function, q) for q in queries]\n\n    avg_precision = mean([r[\"precision\"] for r in results])\n    avg_recall = mean([r[\"recall\"] for r in results])\n    avg_f1 = mean([r[\"f1\"] for r in results])\n\n    return Dict(\n        \"individual_results\" => results,\n        \"average_precision\" => avg_precision,\n        \"average_recall\" => avg_recall,\n        \"average_f1_score\" => avg_f1\n    )\nend","category":"page"},{"location":"adding_search_benchmarks/#The-Meeting-#2","page":"Adding Search Benchmarks","title":"The Meeting #2","text":"","category":"section"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"We had our weekly meeting and there were few suggested edits which we are going to implement :","category":"page"},{"location":"adding_search_benchmarks/","page":"Adding Search Benchmarks","title":"Adding Search Benchmarks","text":"use struct instead of dictionary to return the search results.\njust display the overall result in the terminal and rest all of the detailed results should be written in a text file.\nthe returning struct should also contain integers like total_documents_retrieved, total_relevant_found along with float. \nWrite short, descriptive comments explain the code\nmy mentors has advised me to open a pr, so that other people can see and give their suggestions on the work done till now how here the open pr link : PR Link","category":"page"},{"location":"#Improving-Search-functionality-for-Documenter.jl","page":"Home","title":"Improving Search functionality for Documenter.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This site is a collection of notes, progress reports for the 2025 Google Summer of Code (GSoC) project by @Rahban1, mentored by @mortenpi and @Hetarth02.","category":"page"},{"location":"","page":"Home","title":"Home","text":"I thought it would be a good idea to document my journey using Documenter itself, also I was inspired by my mentor Morten who did the same :)","category":"page"}]
}
