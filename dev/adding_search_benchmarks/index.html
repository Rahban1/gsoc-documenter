<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Adding Search Benchmarks · GSoC Documentation</title><meta name="title" content="Adding Search Benchmarks · GSoC Documentation"/><meta property="og:title" content="Adding Search Benchmarks · GSoC Documentation"/><meta property="twitter:title" content="Adding Search Benchmarks · GSoC Documentation"/><meta name="description" content="Documentation for GSoC Documentation."/><meta property="og:description" content="Documentation for GSoC Documentation."/><meta property="twitter:description" content="Documentation for GSoC Documentation."/><meta property="og:url" content="https://rahban1.github.io/gsoc-documenter/adding_search_benchmarks/"/><meta property="twitter:url" content="https://rahban1.github.io/gsoc-documenter/adding_search_benchmarks/"/><link rel="canonical" href="https://rahban1.github.io/gsoc-documenter/adding_search_benchmarks/"/><script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXXXXXX-X"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-XXXXXXXXX-X', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="GSoC Documentation logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">GSoC Documentation</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Deliverable Summary</span><ul><li class="is-active"><a class="tocitem" href>Adding Search Benchmarks</a><ul class="internal"><li><a class="tocitem" href="#Creating-query-structure"><span>Creating query structure</span></a></li><li><a class="tocitem" href="#Evaluation"><span>Evaluation</span></a></li><li><a class="tocitem" href="#Helper-functions"><span>Helper functions</span></a></li><li><a class="tocitem" href="#The-Meeting-#2"><span>The Meeting #2</span></a></li></ul></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Deliverable Summary</a></li><li class="is-active"><a href>Adding Search Benchmarks</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Adding Search Benchmarks</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/Rahban1/gsoc-documenter" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/Rahban1/gsoc-documenter/blob/main/docs/src/adding_search_benchmarks.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Adding-Search-Benchmarks"><a class="docs-heading-anchor" href="#Adding-Search-Benchmarks">Adding Search Benchmarks</a><a id="Adding-Search-Benchmarks-1"></a><a class="docs-heading-anchor-permalink" href="#Adding-Search-Benchmarks" title="Permalink"></a></h1><p>We had our first meeting, and we discussed what would be the flow of the entire internshiop and also discussed how to go about the first deliverable as per the proposal which is <strong>Adding Search Benchmarks</strong>.  </p><p>We discussed what should be the language of choice for writing scripts for benchmarking, we had two possible candidates, one was Julia (for obvious reasons, since the whole repo is in Julia) and the other one was JavaScript since the search functionality is implemented in JavaScript so it would be easier to interact with the search functionality.  </p><p>We talked about it and thought of JavaScript as a better choice but now I think of it, I belive the barebone architecture for benchmarks should be in Julia only so that in future if anybody want to add more benchmarks or new tests they can do it easily as I am expecting most of the people coming in the Documenter repo are coming from Julia background and as far as talking to the JavaScript based search functionality we can see how to talk it through Julin in coming days.</p><h2 id="Creating-query-structure"><a class="docs-heading-anchor" href="#Creating-query-structure">Creating query structure</a><a id="Creating-query-structure-1"></a><a class="docs-heading-anchor-permalink" href="#Creating-query-structure" title="Permalink"></a></h2><p>First we&#39;ll create a new directory in test folder, I have named it <strong>search</strong>. Inside it I have created the first file named <strong>test_queries.jl</strong></p><p>The file structure look like this :</p><pre><code class="nohighlight hljs">test/
├─search/
│   └─test_queries.jl
...</code></pre><p>I started with creating a basic struct which stores the search query and what should be the expected docs in the following manner :</p><pre><code class="nohighlight hljs">struct TestQuery
    query::String
    expected_docs::Vector{String}
end</code></pre><p>we can then compare it with the actual result and find out the different benchmarks.</p><p>Now we can create different groups of queries like basic queries or queries specific to Julia syntax and if anybody from the community want to test some queries specific to their usecase, they can do it easily. We can then use them all together using something like vcat which will concatenate all the arrays into one</p><h2 id="Evaluation"><a class="docs-heading-anchor" href="#Evaluation">Evaluation</a><a id="Evaluation-1"></a><a class="docs-heading-anchor-permalink" href="#Evaluation" title="Permalink"></a></h2><p>For now, I am using three metrics for calculating benchmarks namely :</p><ul><li>Precision <ul><li>measures how many of the returned results are relevant.</li><li><em>Example</em>: if you returned 5 docs, out of which 3 are relevant, precision = 3/5 = 0.6.</li></ul></li><li>Recall <ul><li>measures how many of the true relevant documents were found in the result.</li><li><em>Example</em>: if there were 4 relevant docs and you returned 3 of them, recall = 3/4 = 0.75.</li></ul></li><li>F1 Score <ul><li>harmonic mean of precision and recall.</li><li>this balances precision and recall in a single number.</li><li><p class="math-container">\[F_1 = 2 \times \frac{\text{precision} \times \text{recall}}{\text{precision} + \text{recall}}\]</p></li></ul></li></ul><h2 id="Helper-functions"><a class="docs-heading-anchor" href="#Helper-functions">Helper functions</a><a id="Helper-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Helper-functions" title="Permalink"></a></h2><p>Now let&#39;s create a function that evaluate all these metrics for a single query</p><p>It&#39;ll look something like this :</p><pre><code class="language-julia hljs">function evaluate_query(search_function, query::TestQuery)
    results = search_function(query.query)

    precision = calculate_precision(results, query.expected_docs)
    recall = calculate_recall(results, query.expected_docs)
    f1 = calculate_f1(precision, recall)

    return Dict(
        &quot;query&quot; =&gt; query.query,
        &quot;precision&quot; =&gt; precision,
        &quot;recall&quot; =&gt; recall,
        &quot;f1&quot; =&gt; f1,
        &quot;expected&quot; =&gt; query.expected_docs,
        &quot;actual&quot; =&gt; results
    )
end</code></pre><p>This will return a dictionary that have all the relevant results. We still have to create the search function that will search the query in our actual search implementation.</p><p>This looks good, now we need to create a function that evaluate all metrics for a suite of queries, which would essentially be calling the <code>evaluate_query</code> function for array of queries, and then calculating the mean of all results for each metric and return a dictionary similar to <code>evaluate_query</code> function</p><p>It look something like this : </p><pre><code class="language-julia hljs">function evaluate_all(search_function, queries)
    results = [evaluate_query(search_function, q) for q in queries]

    avg_precision = mean([r[&quot;precision&quot;] for r in results])
    avg_recall = mean([r[&quot;recall&quot;] for r in results])
    avg_f1 = mean([r[&quot;f1&quot;] for r in results])

    return Dict(
        &quot;individual_results&quot; =&gt; results,
        &quot;average_precision&quot; =&gt; avg_precision,
        &quot;average_recall&quot; =&gt; avg_recall,
        &quot;average_f1_score&quot; =&gt; avg_f1
    )
end</code></pre><h2 id="The-Meeting-#2"><a class="docs-heading-anchor" href="#The-Meeting-#2">The Meeting #2</a><a id="The-Meeting-#2-1"></a><a class="docs-heading-anchor-permalink" href="#The-Meeting-#2" title="Permalink"></a></h2><p>We had our weekly meeting and there were few suggested edits which we are going to implement :</p><ul><li>use struct instead of dictionary to return the search results.</li><li>just display the overall result in the terminal and rest all of the detailed results should be written in a text file.</li><li>the returning struct should also contain integers like <code>total_documents_retrieved, total_relevant_found</code> along with float. </li><li>Write short, descriptive comments explain the code</li><li>my mentors has advised me to open a pr, so that other people can see and give their suggestions on the work done till now how here the open pr link : <a href="https://github.com/JuliaDocs/Documenter.jl/pull/2740">PR Link</a></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Wednesday 11 June 2025 19:44">Wednesday 11 June 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
